# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",files_names)))
}
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
# take only the columns we need
df <- df |>
mutate(
task       = ifelse(grepl("ink_naming", condition), "ink_naming", "word_reading"),
congruency = ifelse(grepl("cong", condition), "congruent", "incongruent"),
acc        = ifelse(participant_response == correct_response, 1, 0)
) |>
mutate(
subject    = as.factor(subject),
task       = as.factor(task),
congruency = as.factor(congruency),
block      = as.numeric(block),
trial      = as.numeric(trial),
acc        = as.numeric(acc),
rt         = as.numeric(rt)
) |>
select(subject, block, trial, task, congruency, participant_response, correct_response, acc, rt)
summary(df)
contrasts(df$task)
contrasts(df$congruency)<-c(1,0)
contrasts(df$congruency)
contrasts(df$congruency)
df$congruency
unique(df$congruency)
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
unique(df$condition)
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
# take only the columns we need
df <- df |>
mutate(
task       = ifelse(grepl("ink_naming", condition), "ink_naming", "word_reading"),
congruency = ifelse(grepl("incong", condition), "congruent", "incongruent"),
acc        = ifelse(participant_response == correct_response, 1, 0)
) |>
mutate(
subject    = as.factor(subject),
task       = as.factor(task),
congruency = as.factor(congruency),
block      = as.numeric(block),
trial      = as.numeric(trial),
acc        = as.numeric(acc),
rt         = as.numeric(rt)
) |>
select(subject, block, trial, task, congruency, participant_response, correct_response, acc, rt)
summary(df)
contrasts(df$task)
contrasts(df$congruency)
save(df, file = "./data/raw_data.rdata")
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
cat("Number of unique subjects:", length(unique(df$subject)))
# Remove NA
df <- df |> filter(!is.na(rt))
# Remove RT outliers (below 300 or above 3000)
df <- df |> filter(rt >= 300 & rt <= 3000)
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
cat("Number of unique subjects:", length(unique(df$subject)))
# Remove NA
df <- df |> filter(!is.na(rt))
# Remove RT outliers (below 300 or above 3000)
df <- df |> filter(rt >= 300 & rt <= 3000)
#
df |>  group_by(subject) |> summarise(trials_count = n(), percentage = (trials_count / nrow(df)) * 100)
hist(df$rt)
library(dplyr)
set.seed(123) # For reproducibility
# Function to generate a single CSV file
generate_csv <- function(subject_id) {
subject <- sprintf("subj%03d", subject_id)
blocks <- rep(1:8, each = 50)
trials <- rep(1:50, times = 8)
condition <- sample(c("ink_naming_cong", "ink_naming_incong",
"word_reading_cong", "word_reading_incong"),
size = 400, replace = TRUE)
correct_response <- sample(c("red", "blue", "green", "yellow"),
size = 400, replace = TRUE)
participant_response <- ifelse(runif(400) < 0.95,
correct_response,
sample(c("red", "blue", "green", "yellow", NA),
size = 400, replace = TRUE,
prob = c(0.23, 0.23, 0.23, 0.23, 0.08)))
rt <- ifelse(is.na(participant_response), NA,
round(rnorm(400,
mean = ifelse(grepl("ink_naming", condition), 1000, 700) +
ifelse(grepl("incong", condition),
ifelse(grepl("ink_naming", condition), 150, 20), 0),
sd = 100)))
# Introduce random NA values in participant_response
na_indices <- sample(1:400, size = sample(0:25, 1), replace = FALSE)
participant_response[na_indices] <- NA
rt[na_indices] <- NA
# Introduce extreme RT values (0-400 and >3000)
extreme_low_indices <- sample(which(!is.na(rt)), size = sample(0:10, 1), replace = FALSE)
extreme_high_indices <- sample(which(!is.na(rt) & !(1:400 %in% extreme_low_indices)), size = sample(0:10, 1), replace = FALSE)
rt[extreme_low_indices] <- sample(0:400, length(extreme_low_indices), replace = TRUE)
rt[extreme_high_indices] <- sample(3000:5000, length(extreme_high_indices), replace = TRUE)
# Adding irrelevant columns
irrelevant_columns <- data.frame(
ip_address = paste0(sample(192:223, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE)),
latitude = runif(400, -90, 90),
longitude = runif(400, -180, 180),
browser_version = sample(c("Chrome"), 400, replace = TRUE),
operating_system = sample(c("Windows"), 400, replace = TRUE),
screen_resolution = paste0(sample(c(1024), 400, replace = TRUE), "x",
sample(c(768), 400, replace = TRUE)),
device_type = sample(c("Desktop"), 400, replace = TRUE),
user_agent = paste0("Agent", sample(1000:9999, 400, replace = TRUE)),
session_id = sample(1:10000, 400, replace = TRUE),
click_rate = runif(400, 0, 0),
error_count = sample(0:0, 400, replace = TRUE)
)
data <- data.frame(
subject = subject,
block = blocks,
trial = trials,
condition = condition,
correct_response = correct_response,
participant_response = participant_response,
rt = rt
) %>%
bind_cols(irrelevant_columns)
write.csv(data, file = paste0("./data/", subject, ".csv"), row.names = FALSE)
}
# Generate 30 CSV files
for (i in 1:30) {
generate_csv(i)
}
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
# take only the columns we need
df <- df |>
mutate(
task       = ifelse(grepl("ink_naming", condition), "ink_naming", "word_reading"),
congruency = ifelse(grepl("incong", condition), "congruent", "incongruent"),
acc        = ifelse(participant_response == correct_response, 1, 0)
) |>
mutate(
subject    = as.factor(subject),
task       = as.factor(task),
congruency = as.factor(congruency),
block      = as.numeric(block),
trial      = as.numeric(trial),
acc        = as.numeric(acc),
rt         = as.numeric(rt)
) |>
select(subject, block, trial, task, congruency, participant_response, correct_response, acc, rt)
summary(df)
library(dplyr)
set.seed(123) # For reproducibility
# Function to generate a single CSV file
generate_csv <- function(subject_id) {
subject <- sprintf("subj%03d", subject_id)
blocks <- rep(1:8, each = 50)
trials <- rep(1:50, times = 8)
condition <- sample(c("ink_naming_cong", "ink_naming_incong",
"word_reading_cong", "word_reading_incong"),
size = 400, replace = TRUE)
correct_response <- sample(c("red", "blue", "green", "yellow"),
size = 400, replace = TRUE)
participant_response <- ifelse(runif(400) < 0.95,
correct_response,
sample(c("red", "blue", "green", "yellow", NA),
size = 400, replace = TRUE,
prob = c(0.23, 0.23, 0.23, 0.23, 0.08)))
rt <- ifelse(is.na(participant_response), NA,
round(rnorm(400,
mean = ifelse(grepl("ink_naming", condition), 1000, 700) +
ifelse(grepl("incong", condition),
ifelse(grepl("ink_naming", condition), 150, 20), 0),
sd = 100)))
# Introduce random NA values in participant_response
na_indices <- sample(1:400, size = sample(0:25, 1), replace = FALSE)
participant_response[na_indices] <- NA
rt[na_indices] <- NA
# Add RT outliers
low_outlier_indices <- sample(which(!is.na(rt)), size = sample(5:10, 1), replace = FALSE)
high_outlier_indices <- sample(which(!is.na(rt) & !(1:400 %in% low_outlier_indices)), size = sample(5:10, 1), replace = FALSE)
rt[low_outlier_indices] <- sample(0:400, length(low_outlier_indices), replace = TRUE)
rt[high_outlier_indices] <- sample(1500:6000, length(high_outlier_indices), replace = TRUE)
# Adding irrelevant columns
irrelevant_columns <- data.frame(
ip_address = paste0(sample(192:223, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE)),
latitude = runif(400, -90, 90),
longitude = runif(400, -180, 180),
browser_version = sample(c("Chrome"), 400, replace = TRUE),
operating_system = sample(c("Windows"), 400, replace = TRUE),
screen_resolution = paste0(sample(c(1024), 400, replace = TRUE), "x",
sample(c(768), 400, replace = TRUE)),
device_type = sample(c("Desktop"), 400, replace = TRUE),
user_agent = paste0("Agent", sample(1000:9999, 400, replace = TRUE)),
session_id = sample(1:10000, 400, replace = TRUE),
click_rate = runif(400, 0, 0),
error_count = sample(0:0, 400, replace = TRUE)
)
data <- data.frame(
subject = subject,
block = blocks,
trial = trials,
condition = condition,
correct_response = correct_response,
participant_response = participant_response,
rt = rt
) %>%
bind_cols(irrelevant_columns)
write.csv(data, file = paste0("./data/", subject, ".csv"), row.names = FALSE)
}
# Generate 30 CSV files
for (i in 1:30) {
generate_csv(i)
}
library(dplyr)
set.seed(123) # For reproducibility
# Function to generate a single CSV file
generate_csv <- function(subject_id) {
subject <- sprintf("subj%03d", subject_id)
blocks <- rep(1:8, each = 50)
trials <- rep(1:50, times = 8)
condition <- sample(c("ink_naming_cong", "ink_naming_incong",
"word_reading_cong", "word_reading_incong"),
size = 400, replace = TRUE)
correct_response <- sample(c("red", "blue", "green", "yellow"),
size = 400, replace = TRUE)
participant_response <- ifelse(runif(400) < 0.95,
correct_response,
sample(c("red", "blue", "green", "yellow", NA),
size = 400, replace = TRUE,
prob = c(0.23, 0.23, 0.23, 0.23, 0.08)))
rt <- ifelse(is.na(participant_response), NA,
round(rnorm(400,
mean = ifelse(grepl("ink_naming", condition), 1000, 700) +
ifelse(grepl("incong", condition),
ifelse(grepl("ink_naming", condition), 150, 20), 0),
sd = 100)))
# Introduce random NA values in participant_response
na_indices <- sample(1:400, size = sample(0:25, 1), replace = FALSE)
participant_response[na_indices] <- NA
rt[na_indices] <- NA
# Add RT outliers
low_outlier_indices <- sample(which(!is.na(rt)), size = sample(5:10, 1), replace = FALSE)
high_outlier_indices <- sample(which(!is.na(rt) & !(1:400 %in% low_outlier_indices)), size = sample(5:10, 1), replace = FALSE)
rt[low_outlier_indices] <- sample(0:400, length(low_outlier_indices), replace = TRUE)
rt[high_outlier_indices] <- sample(1500:6000, length(high_outlier_indices), replace = TRUE)
# Adding irrelevant columns
irrelevant_columns <- data.frame(
ip_address = paste0(sample(192:223, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE)),
latitude = runif(400, -90, 90),
longitude = runif(400, -180, 180),
browser_version = sample(c("Chrome"), 400, replace = TRUE),
operating_system = sample(c("Windows"), 400, replace = TRUE),
screen_resolution = paste0(sample(c(1024), 400, replace = TRUE), "x",
sample(c(768), 400, replace = TRUE)),
device_type = sample(c("Desktop"), 400, replace = TRUE),
user_agent = paste0("Agent", sample(1000:9999, 400, replace = TRUE)),
session_id = sample(1:10000, 400, replace = TRUE),
click_rate = runif(400, 0, 0),
error_count = sample(0:0, 400, replace = TRUE)
)
data <- data.frame(
subject = subject,
block = blocks,
trial = trials,
condition = condition,
correct_response = correct_response,
participant_response = participant_response,
rt = rt
) %>%
bind_cols(irrelevant_columns)
write.csv(data, file = paste0("./data/", subject, ".csv"), row.names = FALSE)
}
# Generate 30 CSV files
for (i in 1:30) {
generate_csv(i)
}
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
# take only the columns we need
df <- df |>
mutate(
task       = ifelse(grepl("ink_naming", condition), "ink_naming", "word_reading"),
congruency = ifelse(grepl("incong", condition), "congruent", "incongruent"),
acc        = ifelse(participant_response == correct_response, 1, 0)
) |>
mutate(
subject    = as.factor(subject),
task       = as.factor(task),
congruency = as.factor(congruency),
block      = as.numeric(block),
trial      = as.numeric(trial),
acc        = as.numeric(acc),
rt         = as.numeric(rt)
) |>
select(subject, block, trial, task, congruency, participant_response, correct_response, acc, rt)
summary(df)
library(dplyr)
set.seed(123) # For reproducibility
# Function to generate a single CSV file
generate_csv <- function(subject_id) {
subject <- sprintf("subj%03d", subject_id)
blocks <- rep(1:8, each = 50)
trials <- rep(1:50, times = 8)
condition <- sample(c("ink_naming_cong", "ink_naming_incong",
"word_reading_cong", "word_reading_incong"),
size = 400, replace = TRUE)
correct_response <- sample(c("red", "blue", "green", "yellow"),
size = 400, replace = TRUE)
participant_response <- ifelse(runif(400) < 0.95,
correct_response,
sample(c("red", "blue", "green", "yellow", NA),
size = 400, replace = TRUE,
prob = c(0.23, 0.23, 0.23, 0.23, 0.08)))
rt <- ifelse(is.na(participant_response), NA,
round(rnorm(400,
mean = ifelse(grepl("ink_naming", condition), 1000, 700) +
ifelse(grepl("incong", condition),
ifelse(grepl("ink_naming", condition), 150, 20), 0),
sd = 100)))
# Introduce random NA values in participant_response
na_indices <- sample(1:400, size = sample(0:25, 1), replace = FALSE)
participant_response[na_indices] <- NA
rt[na_indices] <- NA
# Add RT outliers
low_outlier_indices <- sample(which(!is.na(rt)), size = sample(5:10, 1), replace = FALSE)
high_outlier_indices <- sample(which(!is.na(rt) & !(1:400 %in% low_outlier_indices)), size = sample(5:10, 1), replace = FALSE)
rt[low_outlier_indices] <- sample(0:400, length(low_outlier_indices), replace = TRUE)
rt[high_outlier_indices] <- sample(1500:6000, length(high_outlier_indices), replace = TRUE)
# Adding irrelevant columns
irrelevant_columns <- data.frame(
ip_address = paste0(sample(192:223, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE), ".",
sample(0:255, 400, replace = TRUE)),
latitude = runif(400, -90, 90),
longitude = runif(400, -180, 180),
browser_version = sample(c("Chrome"), 400, replace = TRUE),
operating_system = sample(c("Windows"), 400, replace = TRUE),
screen_resolution = paste0(sample(c(1024), 400, replace = TRUE), "x",
sample(c(768), 400, replace = TRUE)),
device_type = sample(c("Desktop"), 400, replace = TRUE),
user_agent = paste0("Agent", sample(1000:9999, 400, replace = TRUE)),
session_id = sample(1:10000, 400, replace = TRUE),
click_rate = runif(400, 0, 0),
error_count = sample(0:0, 400, replace = TRUE)
)
data <- data.frame(
subject = subject,
block = blocks,
trial = trials,
condition = condition,
correct_response = correct_response,
participant_response = participant_response,
rt = rt
) %>%
bind_cols(irrelevant_columns)
write.csv(data, file = paste0("./data/collected_data/", subject, ".csv"), row.names = FALSE)
}
# Generate 30 CSV files
for (i in 1:30) {
generate_csv(i)
}
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
# take only the columns we need
df <- df |>
mutate(
task       = ifelse(grepl("ink_naming", condition), "ink_naming", "word_reading"),
congruency = ifelse(grepl("incong", condition), "congruent", "incongruent"),
acc        = ifelse(participant_response == correct_response, 1, 0)
) |>
mutate(
subject    = as.factor(subject),
task       = as.factor(task),
congruency = as.factor(congruency),
block      = as.numeric(block),
trial      = as.numeric(trial),
acc        = as.numeric(acc),
rt         = as.numeric(rt)
) |>
select(subject, block, trial, task, congruency, participant_response, correct_response, acc, rt)
summary(df)
contrasts(df$task)
contrasts(df$task)<-c(1,0)
contrasts(df$congruency)
save(df, file = "./data/raw_data.rdata")
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
cat("Number of unique subjects:", length(unique(df$subject)))
# Remove NA
df <- df |> filter(!is.na(rt))
# Remove RT outliers (below 300 or above 3000)
df <- df |> filter(rt >= 300 & rt <= 3000)
#
df |>  group_by(subject) |> summarise(trials_count = n(), percentage = (trials_count / nrow(df)) * 100)
#
df |>  group_by(subject) |> summarise(trials_count = n(), percentage = (trials_count / nrow(df)) * 100) |>  print(n = Inf)
#
df |>  group_by(subject) |> summarise(trials_count = n(), percentage = (trials_count / 400) * 100) |>  print(n = Inf)
#
df |>  group_by(subject) |> summarise(percentage = 1 - (n() / 400)) |>  print(n = Inf)
#check the precntage of remaining trials
df |>  group_by(subject) |> summarise(percentage = 1 - (n() / 400)) |>  print(n = Inf)
save(df, file = "./data/filtered_data.rdata")
library(readr)
subj001 <- read_csv("data/collected_data/subj001.csv")
View(subj001)
load("C:/Users/user/OneDrive - Tel-Aviv University/קורסים/קורס R/פתרונות קורס R/week7_stroop_preprocessing/data/raw_data.rdata")
View(df)
load("C:/Users/user/OneDrive - Tel-Aviv University/קורסים/קורס R/פתרונות קורס R/week7_stroop_preprocessing/data/filtered_data.rdata")
#### CREATE RAW DATA ----
library(dplyr)
# combine files to one df
files_names = dir("./data/collected_data/")
files_names
for (file in files_names) {
print(file)
}
for (file in files_names) {
df <- read.csv(paste0("./data/collected_data/",file))
}
df = data.frame()
for (file in files_names) {
df <- rbind(df, read.csv(paste0("./data/collected_data/",file)))
}
View(df)
grepl("ink_naming", df$condition)
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
cat("Number of unique subjects:", length(unique(df$subject)))
unique(df$subject)
length(unique(df$subject))
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
#### CREATE RAW DATA ----
library(dplyr)
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
cat("Number of unique subjects:", length(unique(df$subject)))
# Remove NA
df <- df |> filter(!is.na(rt))
# Remove RT outliers (below 300 or above 3000)
df <- df |> filter(rt >= 300 & rt <= 3000)
#check the precntage of remaining trials
df |>  group_by(subject) |> summarise(percentage = 1 - (n() / 400)) |>  print(n = Inf)
#### CREATE FILTERD DATA ----
load("./data/raw_data.rdata")
#count participants
df |> group_by(subject) |> summarise(n())
